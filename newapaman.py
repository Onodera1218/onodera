#!/usr/bin/env python
# coding: utf-8

# In[30]:


import pandas as pd  # pandasã‚’ä½¿ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
import numpy as np
import streamlit as st
import subprocess
import pandas as pd
from gspread_dataframe import set_with_dataframe
import json
from google.oauth2.service_account import Credentials
import gspread
import requests
from bs4 import BeautifulSoup


# In[31]:


user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'
header = {'User-Agent': user_agent}

url = 'https://www.chintaistyle.jp/pref/01/area_12293_list.html?page=0&disp=10&item=aprm&ar=asc'
res = requests.get(url, headers=header)
soup = BeautifulSoup(res.text, "html.parser")


# In[32]:


for page in range(1, 5):
    url = 'https://www.chintaistyle.jp/pref/01/area_12293_list.html?page={}'.format(
        page)
    target_url = url.format(page)
    print(target_url)


# In[33]:


soup.find_all('li')


# In[34]:


data = soup.find_all('li', {'class': 'estate-parent-rightBottomUL1_LI1'})


# In[35]:


for li_tag in soup.find_all('li', {'class': 'estate-parent-rightBottomUL1_LI1'}):
    print(li_tag.text)


# In[36]:


#get_ipython().system(' pip install gspread')


# In[37]:


#get_ipython().system(' pip install oauth2client')


# In[38]:


# ãŠæ±ºã¾ã‚Šã®æ–‡å¥
# 2ã¤ã®APIã‚’è¨˜è¿°ã—ãªã„ã¨ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã‚’3600ç§’æ¯ã«ç™ºè¡Œã—ç¶šã‘ãªã‘ã‚Œã°ãªã‚‰ãªã„
scope = ['https://www.googleapis.com/auth/spreadsheets',
         'https://www.googleapis.com/auth/drive']
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸjsonãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«å¤‰æ•°ã«è¨­å®šã€‚
credentials = Credentials.from_service_account_file(
    "quantum-tracker-374208-b7f3ed2fadb7.json", scopes=scope)
# OAuth2ã®è³‡æ ¼æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦Google APIã«ãƒ­ã‚°ã‚¤ãƒ³ã€‚
gc = gspread.authorize(credentials)
# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã‚’å¤‰æ•°ã«æ ¼ç´ã™ã‚‹ã€‚
SPREADSHEET_KEY = '16a7uIbpFfWT0mluRNR17jdHStS-KH6riqufvZAufJSo'
# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆï¼ˆãƒ–ãƒƒã‚¯ï¼‰ã‚’é–‹ã
workbook = gc.open_by_key(SPREADSHEET_KEY)


# In[39]:


# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆï¼ˆãƒ–ãƒƒã‚¯ï¼‰ã‚’é–‹ã
workbook = gc.open_by_key(SPREADSHEET_KEY)
# ã‚·ãƒ¼ãƒˆã®ä¸€è¦§ã‚’å–å¾—ã™ã‚‹ã€‚ï¼ˆãƒªã‚¹ãƒˆå½¢å¼ï¼‰
worksheets = workbook.worksheets()
print(worksheets)
# ã‚·ãƒ¼ãƒˆã‚’é–‹ã
worksheet = workbook.worksheet('12/7-13_ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°')
# ã‚»ãƒ«A1ã«â€test valueâ€ã¨ã„ã†æ–‡å­—åˆ—ã‚’ä»£å…¥ã™ã‚‹ã€‚
worksheet.update_cell(2, 6, 'test')


# In[40]:


# In[41]:


url = 'https://www.chintaistyle.jp/pref/01/area_12293_list.html'  # ã‚µã‚¤ãƒˆã®URLã‚’å–å¾—
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨­å®š
user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'
header = {"User-Agent": user_agent}

res = requests.get(url, headers=header)
soup = BeautifulSoup(res.text, 'html.parser')  # BeautifulSoupã§resã®ä¸­èº«ã‚’æ•´ãˆã‚‹


# In[42]:


address_list = []
for li_tag in soup.find_all('li', {'class': 'estate-parent-rightBottomUL1_LI1'}):
    print(li_tag.text)
    address_list.append(li_tag.text)


# In[43]:


# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
name_df = pd.DataFrame({'ä½æ‰€': address_list})
print(name_df)


# In[44]:


# ãŠæ±ºã¾ã‚Šã®æ–‡å¥
# 2ã¤ã®APIã‚’è¨˜è¿°ã—ãªã„ã¨ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã‚’3600ç§’æ¯ã«ç™ºè¡Œã—ç¶šã‘ãªã‘ã‚Œã°ãªã‚‰ãªã„

scope = ['https://www.googleapis.com/auth/spreadsheets',
         'https://www.googleapis.com/auth/drive']
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸjsonãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«å¤‰æ•°ã«è¨­å®šã€‚
credentials = Credentials.from_service_account_file(
    "quantum-tracker-374208-b7f3ed2fadb7.json", scopes=scope)
# OAuth2ã®è³‡æ ¼æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦Google APIã«ãƒ­ã‚°ã‚¤ãƒ³ã€‚
gc = gspread.authorize(credentials)
# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã‚’å¤‰æ•°ã«æ ¼ç´ã™ã‚‹ã€‚
SPREADSHEET_KEY = '16a7uIbpFfWT0mluRNR17jdHStS-KH6riqufvZAufJSo'
# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆï¼ˆãƒ–ãƒƒã‚¯ï¼‰ã‚’é–‹ã
workbook = gc.open_by_key(SPREADSHEET_KEY)


# In[45]:


#get_ipython().system(' pip install gspread-dataframe')


# In[46]:


set_with_dataframe(workbook.worksheet('12/7-13_ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°'),
                   name_df, row=1, col=6, include_index=True)


# In[47]:


#get_ipython().system(' pip install beautifulsoup4 lxml html5lib')


# In[48]:


# In[49]:


url = 'https://www.city.muroran.lg.jp/main/org4510/akijyoukyou.html'
# èª­ã¿è¾¼ã‚€ã‚µã‚¤ãƒˆã®URLã‚’æ ¼ç´
data = pd.read_html(url, header=0)
data[0].head()


# In[50]:


data[0].tail()


# In[51]:


set_with_dataframe(workbook.worksheet('12/7-13_ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°'),
                   data[0], row=23, col=1, include_index=True)


# In[ ]:

# %%
st.success('æ¡ä»¶ã§çµã‚Šè¾¼ã‚€')
# %%
st.text_input('å…¥å±…å¯èƒ½æ™‚æœŸ')
st.selectbox('å€Ÿå®¶', ('æ™®é€š', 'å®šæœŸ'))
st.selectbox('éƒ¨å±‹ã®åºƒã•', ('ä¸‹é™ãªã—', '10ç•³'))
st.text_input('è·å ´ã®ä½æ‰€ï¼ˆè¿‘ã„ã¨ã“ã‚ã‚’æ¢ã™ï¼‰')
st.selectbox('ç©ºãã®ã‚ã‚‹ä¿è‚²æ‰€ï¼ˆ10kmåœå†…ï¼‰', ('å¸Œæœ›', 'ä¸è¦'))

# %%
st.success('12ä»¶ã€€è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚')
# %%
st.button('Ã— ã‚­ãƒ£ãƒ³ã‚»ãƒ«')
st.button('ğŸ” ã“ã®æ¡ä»¶ã§ã•ãŒã™')
# %%
